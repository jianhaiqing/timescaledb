-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_SUPERUSER
SET ROLE :ROLE_DEFAULT_CLUSTER_USER;
SELECT * FROM add_data_node('data_node1',
                            database => 'data_node1',
                            password => :'ROLE_DEFAULT_CLUSTER_USER_PASS',
                            bootstrap_user => :'ROLE_CLUSTER_SUPERUSER',
                            bootstrap_password => :'ROLE_CLUSTER_SUPERUSER_PASS');
NOTICE:  adding user mapping for "default_cluster_user" to connect to "data_node1"
 node_name  |   host    | port  |  database  | node_created | database_created | extension_created 
------------+-----------+-------+------------+--------------+------------------+-------------------
 data_node1 | localhost | 15432 | data_node1 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node2',
                            database => 'data_node2',
                            password => :'ROLE_DEFAULT_CLUSTER_USER_PASS',
                            bootstrap_user => :'ROLE_CLUSTER_SUPERUSER',
                            bootstrap_password => :'ROLE_CLUSTER_SUPERUSER_PASS');
NOTICE:  adding user mapping for "default_cluster_user" to connect to "data_node2"
 node_name  |   host    | port  |  database  | node_created | database_created | extension_created 
------------+-----------+-------+------------+--------------+------------------+-------------------
 data_node2 | localhost | 15432 | data_node2 | t            | t                | t
(1 row)

SELECT * FROM add_data_node('data_node3',
                            database => 'data_node3',
                            password => :'ROLE_DEFAULT_CLUSTER_USER_PASS',
                            bootstrap_user => :'ROLE_CLUSTER_SUPERUSER',
                            bootstrap_password => :'ROLE_CLUSTER_SUPERUSER_PASS');
NOTICE:  adding user mapping for "default_cluster_user" to connect to "data_node3"
 node_name  |   host    | port  |  database  | node_created | database_created | extension_created 
------------+-----------+-------+------------+--------------+------------------+-------------------
 data_node3 | localhost | 15432 | data_node3 | t            | t                | t
(1 row)

\des+
                                                                       List of foreign servers
    Name    |        Owner         | Foreign-data wrapper | Access privileges | Type | Version |                      FDW options                      | Description 
------------+----------------------+----------------------+-------------------+------+---------+-------------------------------------------------------+-------------
 data_node1 | default_cluster_user | timescaledb_fdw      |                   |      |         | (host 'localhost', port '15432', dbname 'data_node1') | 
 data_node2 | default_cluster_user | timescaledb_fdw      |                   |      |         | (host 'localhost', port '15432', dbname 'data_node2') | 
 data_node3 | default_cluster_user | timescaledb_fdw      |                   |      |         | (host 'localhost', port '15432', dbname 'data_node3') | 
(3 rows)

RESET ROLE;
CREATE FUNCTION _timescaledb_internal.invoke_distributed_commands()
RETURNS void
AS :TSL_MODULE_PATHNAME, 'tsl_invoke_distributed_commands'
LANGUAGE C STRICT;
CREATE FUNCTION _timescaledb_internal.invoke_faulty_distributed_command()
RETURNS void
AS :TSL_MODULE_PATHNAME, 'tsl_invoke_faulty_distributed_command'
LANGUAGE C STRICT;
SET ROLE :ROLE_DEFAULT_CLUSTER_USER;
SELECT _timescaledb_internal.invoke_distributed_commands();
INFO:  data_node1 result: PGRES_COMMAND_OK
INFO:  data_node2 result: PGRES_COMMAND_OK
INFO:  data_node3 result: PGRES_COMMAND_OK
INFO:  data_node1 result: PGRES_COMMAND_OK
INFO:  data_node2 result: PGRES_COMMAND_OK
INFO:  data_node1 result: PGRES_COMMAND_OK
INFO:  data_node2 result: PGRES_COMMAND_OK
 invoke_distributed_commands 
-----------------------------
 
(1 row)

\c data_node1
\dt
                 List of relations
 Schema |    Name    | Type  |        Owner         
--------+------------+-------+----------------------
 public | disttable1 | table | default_cluster_user
 public | disttable2 | table | default_cluster_user
(2 rows)

SELECT * FROM disttable1;
             time             | device | temp  
------------------------------+--------+-------
 Sat Sep 18 00:00:00 1976 PDT |     47 | 103.4
(1 row)

\c data_node2
\dt
                 List of relations
 Schema |    Name    | Type  |        Owner         
--------+------------+-------+----------------------
 public | disttable1 | table | default_cluster_user
 public | disttable2 | table | default_cluster_user
(2 rows)

SELECT * FROM disttable1;
             time             | device | temp  
------------------------------+--------+-------
 Sat Sep 18 00:00:00 1976 PDT |     47 | 103.4
(1 row)

\c data_node3
\dt
                 List of relations
 Schema |    Name    | Type  |        Owner         
--------+------------+-------+----------------------
 public | disttable1 | table | default_cluster_user
(1 row)

SELECT * FROM disttable1;
 time | device | temp 
------+--------+------
(0 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
SET ROLE :ROLE_DEFAULT_CLUSTER_USER;
-- Verify failed insert command gets fully rolled back
\set ON_ERROR_STOP 0
SELECT _timescaledb_internal.invoke_faulty_distributed_command();
ERROR:  [data_node3]: relation "public.disttable2" does not exist
\set ON_ERROR_STOP 1
\c data_node1
SELECT * from disttable2;
 time | device | temp 
------+--------+------
(0 rows)

\c data_node2
SELECT * from disttable2;
 time | device | temp 
------+--------+------
(0 rows)

-- Test connection session identity
\c :TEST_DBNAME :ROLE_SUPERUSER
\unset ECHO
psql:include/remote_exec.sql:5: NOTICE:  schema "test" already exists, skipping
-- Register is_frontend_session() function and test that it returns false for
-- connections openned by test suite. This simualates behaviour expected
-- with a client connections.
CREATE OR REPLACE FUNCTION is_frontend_session()
RETURNS BOOL
AS :TSL_MODULE_PATHNAME, 'test_is_frontend_session' LANGUAGE C;
\c data_node1
CREATE OR REPLACE FUNCTION is_frontend_session()
RETURNS BOOL
AS :TSL_MODULE_PATHNAME, 'test_is_frontend_session' LANGUAGE C;
SELECT is_frontend_session();
 is_frontend_session 
---------------------
 f
(1 row)

\c data_node2
CREATE OR REPLACE FUNCTION is_frontend_session()
RETURNS BOOL
AS :TSL_MODULE_PATHNAME, 'test_is_frontend_session' LANGUAGE C;
SELECT is_frontend_session();
 is_frontend_session 
---------------------
 f
(1 row)

\c data_node3
CREATE OR REPLACE FUNCTION is_frontend_session()
RETURNS BOOL
AS :TSL_MODULE_PATHNAME, 'test_is_frontend_session' LANGUAGE C;
SELECT is_frontend_session();
 is_frontend_session 
---------------------
 f
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
SET ROLE :ROLE_DEFAULT_CLUSTER_USER;
SELECT is_frontend_session();
 is_frontend_session 
---------------------
 f
(1 row)

-- Ensure peer dist id is already set and can be set only once
\set ON_ERROR_STOP 0
SELECT * FROM test.remote_exec('{data_node1}', $$ SELECT * FROM _timescaledb_internal.set_peer_dist_id('77348176-09da-4a80-bc78-e31bdf5e63ec'); $$);
NOTICE:  [data_node1]:  SELECT * FROM _timescaledb_internal.set_peer_dist_id('77348176-09da-4a80-bc78-e31bdf5e63ec')
ERROR:  [data_node1]: distributed peer ID already set
\set ON_ERROR_STOP 1
-- Repeat is_frontend_session() test again, but this time using connections openned from frontend
-- to backend nodes. Must return true.
SELECT * FROM test.remote_exec(NULL, $$ SELECT is_frontend_session(); $$);
NOTICE:  [data_node1]:  SELECT is_frontend_session()
NOTICE:  [data_node1]:
is_frontend_session
-------------------
t                  
(1 row)


NOTICE:  [data_node2]:  SELECT is_frontend_session()
NOTICE:  [data_node2]:
is_frontend_session
-------------------
t                  
(1 row)


NOTICE:  [data_node3]:  SELECT is_frontend_session()
NOTICE:  [data_node3]:
is_frontend_session
-------------------
t                  
(1 row)


 remote_exec 
-------------
 
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
DROP DATABASE data_node1;
DROP DATABASE data_node2;
DROP DATABASE data_node3;
